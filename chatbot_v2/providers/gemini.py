"""
Google Gemini AI Provider Implementation
Connects to Google AI (Gemini) API for free-tier LLM access
"""
import asyncio
import aiohttp
import json
import time
from typing import Dict, Any, Optional
from datetime import datetime

from ..ai_providers import AIProvider, AIRequest, AIResponse
from ..config import DEFAULT_AI_MODEL


class GeminiProvider(AIProvider):
    """Google Gemini AI provider for free-tier cloud models"""

    # Gemini API pricing (for tracking, free tier = $0)
    # Flash models are free up to rate limits
    PRICING = {
        'gemini-2.0-flash-exp': {'input': 0, 'output': 0},  # Free tier BEST: 1,500 RPD, 15 RPM
        'gemini-2.0-flash': {'input': 0, 'output': 0},  # Free tier: 1,500 RPD
        'gemini-2.5-flash': {'input': 0, 'output': 0},  # Free tier: 500 RPD
        'gemini-2.5-pro': {'input': 0, 'output': 0},  # Free tier (limited): 100 RPD
        'gemini-1.5-flash': {'input': 0, 'output': 0},  # Legacy
        'gemini-1.5-pro': {'input': 0, 'output': 0},  # Legacy
    }

    def __init__(self, api_key: str, model: str = None):
        # Use DEFAULT_AI_MODEL from config if no model specified
        default = model or DEFAULT_AI_MODEL
        super().__init__("gemini", {"api_key": api_key, "model": default})
        self.api_key = api_key
        self.default_model = default
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"

    async def generate(self, request: AIRequest) -> AIResponse:
        """Generate response using Gemini API"""
        start_time = time.time()

        print(f"ðŸŒŸ GEMINI PROVIDER: generate() called with request.model='{request.model}'")

        if not self.api_key:
            print(f"âŒ GEMINI PROVIDER: No API key configured!")
            return AIResponse(
                content="",
                model=request.model,
                provider=self.name,
                error="Gemini API key not configured"
            )

        try:
            # Determine which model to use
            model = request.model if request.model and 'gemini' in request.model else self.default_model
            print(f"ðŸ” GEMINI PROVIDER: Selected model='{model}' (request had '{request.model}', default is '{self.default_model}')")

            # Ensure model name doesn't already have "models/" prefix
            if not model.startswith('models/'):
                model_path = f"models/{model}"
            else:
                model_path = model

            # Prepare the prompt
            full_prompt = request.prompt
            if request.system_prompt:
                full_prompt = f"{request.system_prompt}\n\n{request.prompt}"

            # Gemini API payload format
            payload = {
                "contents": [{
                    "parts": [{
                        "text": full_prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": request.temperature,
                    "maxOutputTokens": request.max_tokens,
                    "topP": 0.95,
                    "topK": 40
                }
            }

            # API endpoint with proper model path
            endpoint = f"{self.base_url}/{model_path}:generateContent?key={self.api_key}"
            print(f"ðŸš€ GEMINI PROVIDER: Calling API endpoint: {self.base_url}/{model_path}:generateContent")

            # Make request to Gemini
            timeout = aiohttp.ClientTimeout(total=request.timeout_seconds)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(endpoint, json=payload) as response:
                    response_text = await response.text()

                    if response.status != 200:
                        # Parse error message
                        try:
                            error_data = json.loads(response_text)
                            error_message = error_data.get('error', {}).get('message', response_text)
                        except:
                            error_message = response_text

                        print(f"âŒ GEMINI PROVIDER: API returned error {response.status}: {error_message}")
                        return AIResponse(
                            content="",
                            model=model,
                            provider=self.name,
                            error=f"Gemini API error ({response.status}): {error_message}"
                        )

                    data = json.loads(response_text)

                    # Extract response from Gemini's nested structure
                    try:
                        candidates = data.get('candidates', [])
                        if not candidates:
                            return AIResponse(
                                content="",
                                model=model,
                                provider=self.name,
                                error="No response generated by Gemini"
                            )

                        content = candidates[0].get('content', {}).get('parts', [{}])[0].get('text', '').strip()

                        # Clean up common AI formatting issues
                        if content.startswith("```sql\n"):
                            content = content[6:]
                        elif content.startswith("```\n"):
                            content = content[4:]
                        if content.endswith("\n```"):
                            content = content[:-4]

                        # Get token usage
                        usage_metadata = data.get('usageMetadata', {})
                        prompt_tokens = usage_metadata.get('promptTokenCount', 0)
                        completion_tokens = usage_metadata.get('candidatesTokenCount', 0)
                        total_tokens = prompt_tokens + completion_tokens

                        response_time_ms = int((time.time() - start_time) * 1000)

                        # Calculate cost (free tier = $0, but track for future)
                        cost_cents = self.calculate_cost(prompt_tokens, completion_tokens, model)

                        print(f"âœ… GEMINI PROVIDER: Success! Generated {len(content)} chars in {response_time_ms}ms, {total_tokens} tokens")

                        return AIResponse(
                            content=content,
                            model=model,
                            provider=self.name,
                            tokens_used=total_tokens,
                            cost_cents=cost_cents,
                            response_time_ms=response_time_ms,
                            metadata={
                                "prompt_tokens": prompt_tokens,
                                "completion_tokens": completion_tokens,
                                "finish_reason": candidates[0].get('finishReason', 'UNKNOWN')
                            }
                        )

                    except (KeyError, IndexError) as e:
                        return AIResponse(
                            content="",
                            model=model,
                            provider=self.name,
                            error=f"Failed to parse Gemini response: {str(e)}"
                        )

        except asyncio.TimeoutError:
            return AIResponse(
                content="",
                model=request.model,
                provider=self.name,
                error="Request timed out"
            )
        except Exception as e:
            return AIResponse(
                content="",
                model=request.model,
                provider=self.name,
                error=f"Gemini connection error: {str(e)}"
            )

    def check_availability(self) -> bool:
        """Check if Gemini API is available"""
        if not self.api_key:
            self.is_available = False
            self.last_check = datetime.now()
            return False

        try:
            import requests

            # List models to check API availability
            endpoint = f"{self.base_url}/models?key={self.api_key}"
            response = requests.get(endpoint, timeout=5)

            self.is_available = response.status_code == 200
            self.last_check = datetime.now()
            return self.is_available
        except Exception as e:
            print(f"Gemini availability check failed: {e}")
            self.is_available = False
            self.last_check = datetime.now()
            return False

    def get_available_models(self) -> list[str]:
        """Get list of available Gemini models"""
        try:
            import requests

            # Fetch list of all models from API
            endpoint = f"{self.base_url}/models?key={self.api_key}"
            response = requests.get(endpoint, timeout=5)

            if response.status_code != 200:
                return self._get_default_models()

            data = response.json()
            models = data.get('models', [])

            # Filter for models that support content generation
            available = []
            for model in models:
                name = model.get('name', '')
                methods = model.get('supportedGenerationMethods', [])

                # Only include models that support generateContent
                if 'generateContent' in methods and 'gemini' in name.lower():
                    # Remove "models/" prefix for cleaner names
                    model_name = name.replace('models/', '')
                    available.append(model_name)

            return available if available else self._get_default_models()

        except Exception as e:
            print(f"Failed to fetch Gemini models: {e}")
            return self._get_default_models()

    def _get_default_models(self) -> list[str]:
        """Return default Gemini models as fallback"""

        # Return the current generation free-tier models
        return [
            'gemini-2.5-flash',      # Fastest, newest (2.5)
            'gemini-2.0-flash',      # Fast and reliable (2.0)
            'gemini-2.5-pro'         # Best quality, lower limits
        ]

    def calculate_cost(self, input_tokens: int, output_tokens: int, model: str) -> int:
        """Calculate cost in cents for the given token usage"""
        # Free tier = $0, but track structure for future paid tier
        pricing = self.PRICING.get(model, {'input': 0, 'output': 0})

        # Cost per million tokens in dollars
        input_cost = (input_tokens / 1_000_000) * pricing['input']
        output_cost = (output_tokens / 1_000_000) * pricing['output']

        # Convert to cents
        total_cost_cents = int((input_cost + output_cost) * 100)

        return total_cost_cents


# Helper function to create and configure Gemini provider
def create_gemini_provider(api_key: str, model: str = 'gemini-2.5-flash') -> GeminiProvider:
    """Create and configure a Gemini provider"""
    provider = GeminiProvider(api_key, model)
    provider.check_availability()
    return provider
